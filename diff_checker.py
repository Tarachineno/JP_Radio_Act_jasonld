#!/usr/bin/env python3
"""
æ³•è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å·®åˆ†ç¢ºèªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

e-Govã¨Japanese Law Translationã‹ã‚‰æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€
æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦å·®åˆ†ã‚’æ¤œå‡ºã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import os
import hashlib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import requests
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
import xml.etree.ElementTree as ET
from xml.dom import minidom

console = Console()


@dataclass
class DiffResult:
    """å·®åˆ†æ¤œå‡ºçµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    source: str
    timestamp: str
    has_changes: bool
    old_hash: Optional[str]
    new_hash: Optional[str]
    changes: List[str]
    error: Optional[str] = None


class LawDiffChecker:
    """æ³•è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®å·®åˆ†ç¢ºèªã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir: str = "data", cache_file: str = "diff_cache.json"):
        self.data_dir = Path(data_dir)
        self.cache_file = self.data_dir / cache_file
        self.data_dir.mkdir(exist_ok=True)
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('diff_checker.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿
        self.cache = self._load_cache()
    
    def _load_cache(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return {}
    
    def _save_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—: {e}")
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        if not file_path.exists():
            return ""
        
        hash_md5 = hashlib.md5()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _download_file(self, url: str, filename: str) -> Optional[Path]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            file_path = self.data_dir / filename
            
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            if url.endswith('.zip'):
                import zipfile
                import io
                
                with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
                    # law.xmlã‚’æ¢ã™
                    xml_files = [f for f in zip_file.namelist() if f.endswith('.xml')]
                    if xml_files:
                        with zip_file.open(xml_files[0]) as xml_file:
                            with open(file_path, 'wb') as f:
                                f.write(xml_file.read())
                    else:
                        self.logger.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã«XMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {url}")
                        return None
            else:
                with open(file_path, 'wb') as f:
                    f.write(response.content)
            
            self.logger.info(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {filename}")
            return file_path
            
        except Exception as e:
            self.logger.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— {url}: {e}")
            return None
    
    def _normalize_xml(self, file_path: Path) -> Path:
        """XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£è¦åŒ–"""
        try:
            # XMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å†æ§‹ç¯‰
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # ç¾ã—ã„å½¢å¼ã§å‡ºåŠ›
            xml_str = minidom.parseString(ET.tostring(root, encoding='unicode')).toprettyxml(
                indent="  ", encoding='utf-8'
            )
            
            # BOMã‚’é™¤å»ã—ã¦LFã«çµ±ä¸€
            xml_str = xml_str.replace(b'\xef\xbb\xbf', b'')  # BOMé™¤å»
            xml_str = xml_str.replace(b'\r\n', b'\n')  # CRLF â†’ LF
            
            # test.xml â†’ test.normalized.xml
            normalized_path = file_path.with_name(file_path.stem + '.normalized' + file_path.suffix)
            with open(normalized_path, 'wb') as f:
                f.write(xml_str)
            
            return normalized_path
            
        except Exception as e:
            self.logger.error(f"XMLæ­£è¦åŒ–å¤±æ•— {file_path}: {e}")
            return file_path
    
    def _extract_metadata(self, file_path: Path) -> Dict[str, Any]:
        """XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            metadata = {}
            
            # åŸºæœ¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            for elem in root.iter():
                if elem.tag.endswith('LawNum'):
                    metadata['law_number'] = elem.text
                elif elem.tag.endswith('LawName'):
                    metadata['law_name'] = elem.text
                elif elem.tag.endswith('EnactDate'):
                    metadata['enact_date'] = elem.text
                elif elem.tag.endswith('EnforcementDate'):
                    metadata['enforcement_date'] = elem.text
            
            return metadata
            
        except Exception as e:
            self.logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•— {file_path}: {e}")
            return {}
    
    def check_japanese_law_diff(self, url: str) -> DiffResult:
        """æ—¥æœ¬èªæ³•è¦ã®å·®åˆ†ã‚’ç¢ºèª"""
        self.logger.info("æ—¥æœ¬èªæ³•è¦ã®å·®åˆ†ç¢ºèªã‚’é–‹å§‹")
        
        result = DiffResult(
            source="Japanese Law",
            timestamp=datetime.now().isoformat(),
            has_changes=False,
            old_hash=None,
            new_hash=None,
            changes=[],
            error=None
        )
        
        try:
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—
            existing_file = self.data_dir / "RadioAct_ja.xml"
            if existing_file.exists():
                result.old_hash = self._calculate_file_hash(existing_file)
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            temp_file = self._download_file(url, "RadioAct_ja_temp.xml")
            if not temp_file:
                result.error = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—"
                return result
            
            # æ­£è¦åŒ–
            normalized_temp = self._normalize_xml(temp_file)
            result.new_hash = self._calculate_file_hash(normalized_temp)
            
            # å·®åˆ†ç¢ºèª
            if result.old_hash and result.new_hash:
                if result.old_hash != result.new_hash:
                    result.has_changes = True
                    result.changes.append("ãƒãƒƒã‚·ãƒ¥å€¤ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ")
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚‚ç¢ºèª
                    old_metadata = {}
                    if existing_file.exists():
                        old_metadata = self._extract_metadata(existing_file)
                    
                    new_metadata = self._extract_metadata(normalized_temp)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚’æ¤œå‡º
                    for key in set(old_metadata.keys()) | set(new_metadata.keys()):
                        if old_metadata.get(key) != new_metadata.get(key):
                            result.changes.append(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ '{key}' ãŒå¤‰æ›´: {old_metadata.get(key)} â†’ {new_metadata.get(key)}")
                else:
                    result.changes.append("å¤‰æ›´ãªã—")
            else:
                result.changes.append("åˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            # æˆåŠŸã—ãŸå ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãæ›ãˆ
            if not result.error:
                if existing_file.exists():
                    existing_file.unlink()
                normalized_temp.rename(existing_file)
                temp_file.unlink(missing_ok=True)
            
        except Exception as e:
            result.error = str(e)
            self.logger.error(f"æ—¥æœ¬èªæ³•è¦å·®åˆ†ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def check_english_law_diff(self, url: str) -> DiffResult:
        """è‹±èªæ³•è¦ã®å·®åˆ†ã‚’ç¢ºèª"""
        self.logger.info("è‹±èªæ³•è¦ã®å·®åˆ†ç¢ºèªã‚’é–‹å§‹")
        
        result = DiffResult(
            source="English Law",
            timestamp=datetime.now().isoformat(),
            has_changes=False,
            old_hash=None,
            new_hash=None,
            changes=[],
            error=None
        )
        
        try:
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—
            existing_file = self.data_dir / "RadioAct_en.xml"
            if existing_file.exists():
                result.old_hash = self._calculate_file_hash(existing_file)
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            temp_file = self._download_file(url, "RadioAct_en_temp.xml")
            if not temp_file:
                result.error = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—"
                return result
            
            # æ­£è¦åŒ–
            normalized_temp = self._normalize_xml(temp_file)
            result.new_hash = self._calculate_file_hash(normalized_temp)
            
            # å·®åˆ†ç¢ºèª
            if result.old_hash and result.new_hash:
                if result.old_hash != result.new_hash:
                    result.has_changes = True
                    result.changes.append("ãƒãƒƒã‚·ãƒ¥å€¤ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ")
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚‚ç¢ºèª
                    old_metadata = {}
                    if existing_file.exists():
                        old_metadata = self._extract_metadata(existing_file)
                    
                    new_metadata = self._extract_metadata(normalized_temp)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚’æ¤œå‡º
                    for key in set(old_metadata.keys()) | set(new_metadata.keys()):
                        if old_metadata.get(key) != new_metadata.get(key):
                            result.changes.append(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ '{key}' ãŒå¤‰æ›´: {old_metadata.get(key)} â†’ {new_metadata.get(key)}")
                else:
                    result.changes.append("å¤‰æ›´ãªã—")
            else:
                result.changes.append("åˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            # æˆåŠŸã—ãŸå ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãæ›ãˆ
            if not result.error:
                if existing_file.exists():
                    existing_file.unlink()
                normalized_temp.rename(existing_file)
                temp_file.unlink(missing_ok=True)
            
        except Exception as e:
            result.error = str(e)
            self.logger.error(f"è‹±èªæ³•è¦å·®åˆ†ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def check_all_diffs(self, ja_url: str, en_url: str) -> List[DiffResult]:
        """å…¨ã¦ã®å·®åˆ†ã‚’ç¢ºèª"""
        results = []
        
        # æ—¥æœ¬èªæ³•è¦ã®å·®åˆ†ç¢ºèª
        ja_result = self.check_japanese_law_diff(ja_url)
        results.append(ja_result)
        
        # è‹±èªæ³•è¦ã®å·®åˆ†ç¢ºèª
        en_result = self.check_english_law_diff(en_url)
        results.append(en_result)
        
        # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.cache['last_check'] = {
            'timestamp': datetime.now().isoformat(),
            'results': [asdict(result) for result in results]
        }
        self._save_cache()
        
        return results
    
    def display_results(self, results: List[DiffResult]):
        """çµæœã‚’è¡¨ç¤º"""
        console.print("\n[bold blue]æ³•è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å·®åˆ†ç¢ºèªçµæœ[/bold blue]\n")
        
        for result in results:
            # çµæœãƒ‘ãƒãƒ«ã‚’ä½œæˆ
            if result.error:
                status = Text("âŒ ã‚¨ãƒ©ãƒ¼", style="red")
                content = f"ã‚¨ãƒ©ãƒ¼: {result.error}"
            elif result.has_changes:
                status = Text("ğŸ”„ å¤‰æ›´ã‚ã‚Š", style="yellow")
                content = "\n".join(result.changes)
            else:
                status = Text("âœ… å¤‰æ›´ãªã—", style="green")
                content = "\n".join(result.changes)
            
            panel = Panel(
                f"[bold]{result.source}[/bold]\n"
                f"æ™‚åˆ»: {result.timestamp}\n"
                f"çŠ¶æ…‹: {status}\n"
                f"å¤‰æ›´å†…å®¹:\n{content}",
                title=f"å·®åˆ†ç¢ºèªçµæœ - {result.source}",
                border_style="blue"
            )
            console.print(panel)
        
        # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        table = Table(title="å·®åˆ†ç¢ºèªã‚µãƒãƒªãƒ¼")
        table.add_column("ã‚½ãƒ¼ã‚¹", style="cyan")
        table.add_column("çŠ¶æ…‹", style="magenta")
        table.add_column("å¤‰æ›´æ•°", style="green")
        
        for result in results:
            status = "ã‚¨ãƒ©ãƒ¼" if result.error else ("å¤‰æ›´ã‚ã‚Š" if result.has_changes else "å¤‰æ›´ãªã—")
            change_count = len(result.changes)
            table.add_row(result.source, status, str(change_count))
        
        console.print(table)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ³•è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å·®åˆ†ç¢ºèªãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--ja-url", default="https://elaws.e-gov.go.jp/api/1/lawdata/325AC0000000131", 
                       help="æ—¥æœ¬èªæ³•è¦XMLã®URL")
    parser.add_argument("--en-url", default="https://www.japaneselawtranslation.go.jp/common/data/law/325AC0000000131.zip",
                       help="è‹±èªæ³•è¦XMLã®URL")
    parser.add_argument("--data-dir", default="data", help="ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--cache-file", default="diff_cache.json", help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«")
    
    args = parser.parse_args()
    
    # å·®åˆ†ç¢ºèªå®Ÿè¡Œ
    checker = LawDiffChecker(args.data_dir, args.cache_file)
    results = checker.check_all_diffs(args.ja_url, args.en_url)
    
    # çµæœè¡¨ç¤º
    checker.display_results(results)
    
    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã¯çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã‚’è¿”ã™
    if any(result.has_changes for result in results):
        return 1
    return 0


if __name__ == "__main__":
    exit(main()) 